{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e383fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9bdf5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# img = cv2.imread('WIN_20201209_17_25_54_Pro.jpg')\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "# for (x,y,w,h) in faces:\n",
    "#     img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#     roi_gray = gray[y:y+h, x:x+w]\n",
    "#     roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66da8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# various configurations for plotting and logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3545c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import img_as_ubyte, io, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bb085bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(path):\n",
    "    if not os.path.exists(path):\n",
    "        logger.info('Please download training/testing data to CW_Dataset directory')\n",
    "        return None\n",
    "    else:\n",
    "        images = list()\n",
    "        labels = list()\n",
    "        \n",
    "    file_list = np.genfromtxt(path + '/labels/list_label_train.txt', dtype=str)    \n",
    "    logger.info(f\"Loading {len(file_list)} images\")\n",
    "    for f_name, label in file_list:\n",
    "        img = io.imread(os.path.join(path, 'train', f_name.split('.jpg')[0]+'_aligned.jpg'))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            logger.info(f'Error loading image at {f_name}')\n",
    "    logger.info(f'Successfully loaded {len(images)} images')\n",
    "    return images, labels\n",
    "            \n",
    "path = '../../CW_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f0aa99eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading 12271 images\n",
      "INFO:__main__:Successfully loaded 12271 images\n"
     ]
    }
   ],
   "source": [
    "X, y = load_training_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3225e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a1b6ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIFT():\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.sift = cv2.SIFT_create()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        des_arr = list()\n",
    "        y_list = list()\n",
    "        logger.info('Beginning SIFT transformations')\n",
    "        for i in range(len(X)):\n",
    "            img = img_as_ubyte(color.rgb2gray(X[i]))\n",
    "            kp, des = self.sift.detectAndCompute(img, None)\n",
    "            \n",
    "            if des is not None:\n",
    "                des_arr.append(des)\n",
    "                y_list.append(y[i])       \n",
    "        return des_arr, y_list\n",
    "    \n",
    "    def fit_transform(self, X, y, **fit_params):\n",
    "        return self.fit(X).transform(X, y=y)\n",
    "    \n",
    "    \n",
    "class MiniKMeans():\n",
    "    def __init__(self):\n",
    "        self.num_clusters = None\n",
    "        self.batch_size = None\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, X, y, *args, **kwargs):\n",
    "        X = np.vstack(X)\n",
    "        self.num_clusters = len(np.unique(y)) * 10\n",
    "        self.batch_size = X.shape[0] // 4\n",
    "        self.model = MiniBatchKMeans(n_clusters=self.num_clusters, batch_size=self.batch_size).fit(X)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):  \n",
    "        hist_list = list()\n",
    "        for des in X:\n",
    "            hist = np.zeros(self.num_clusters)\n",
    "            idx =  self.model.predict(des)\n",
    "            for j in idx:\n",
    "                hist[j] = hist[j] + (1 / len(des))\n",
    "            \n",
    "            hist_list.append(hist)\n",
    "        return np.vstack(hist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d07609f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionRecSVC():\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.model = None\n",
    "        \n",
    "    def fit_transform(self, X, y):\n",
    "        X, y = SIFT(10).fit_transform(X, y)\n",
    "        X = MiniKMeans().fit(X, y).transform(X)\n",
    "        \n",
    "        self.model = svm.SVC(kernel=self.kernel)\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "        \n",
    "    def predict(X, y):\n",
    "        pass\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b2bafd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmotionRecSVC('rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ad00a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Beginning SIFT transformations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmotionRecSVC at 0x21b5f34d850>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db46b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "\n",
    "class EmotionRecMLP:\n",
    "    pass\n",
    "\n",
    "class EmotionRecCNN(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6627217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6867\u001b[0m       \u001b[32m0.6150\u001b[0m        \u001b[35m0.6808\u001b[0m  0.0470\n",
      "      2        \u001b[36m0.6783\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m0.6745\u001b[0m  0.0130\n",
      "      3        \u001b[36m0.6617\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.6653\u001b[0m  0.0120\n",
      "      4        \u001b[36m0.6559\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.6557\u001b[0m  0.0120\n",
      "      5        \u001b[36m0.6469\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6468\u001b[0m  0.0130\n",
      "      6        \u001b[36m0.6382\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6356\u001b[0m  0.0120\n",
      "      7        \u001b[36m0.6325\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6233\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6164\u001b[0m       0.7150        \u001b[35m0.6112\u001b[0m  0.0120\n",
      "      9        0.6258       \u001b[32m0.7200\u001b[0m        \u001b[35m0.6059\u001b[0m  0.0140\n",
      "     10        0.6167       \u001b[32m0.7250\u001b[0m        \u001b[35m0.6005\u001b[0m  0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "<ipython-input-6-467d7b16a0d1>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "\n",
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_units=10, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X))\n",
    "        return X\n",
    "\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "net.fit(X, y)\n",
    "y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "001b5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "torch.manual_seed(360);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ad47b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been downloaded and extracted to datasets.\n"
     ]
    }
   ],
   "source": [
    "def download_and_extract_data(dataset_dir='datasets'):\n",
    "    data_zip = os.path.join(dataset_dir, 'hymenoptera_data.zip')\n",
    "    data_path = os.path.join(dataset_dir, 'hymenoptera_data')\n",
    "    url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        if not os.path.exists(data_zip):\n",
    "            print(\"Starting to download data...\")\n",
    "            data = request.urlopen(url, timeout=15).read()\n",
    "            with open(data_zip, 'wb') as f:\n",
    "                f.write(data)\n",
    "\n",
    "        print(\"Starting to extract data...\")\n",
    "        with ZipFile(data_zip, 'r') as zip_f:\n",
    "            zip_f.extractall(dataset_dir)\n",
    "        \n",
    "    print(\"Data has been downloaded and extracted to {}.\".format(dataset_dir))\n",
    "    \n",
    "download_and_extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14101449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'datasets/hymenoptera_data'\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train'), train_transforms)\n",
    "val_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'val'), val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa66a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c41099ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "lrscheduler = LRScheduler(\n",
    "    policy='StepLR', step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dd73683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Checkpoint\n",
    "\n",
    "checkpoint = Checkpoint(\n",
    "    f_params='best_model.pt', monitor='valid_acc_best')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65a1cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Freezer\n",
    "\n",
    "freezer = Freezer(lambda x: not x.startswith('model.fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0edf71b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\brenner\\documents\\python_projects\\emotion_recognition\\venv\\lib\\site-packages\\skorch\\net.py:1536: UserWarning: You set iterator_valid__shuffle=True; this is most likely not what you want because the values returned by predict and predict_proba will be shuffled.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    PretrainedModel, \n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    lr=0.001,\n",
    "    batch_size=4,\n",
    "    max_epochs=25,\n",
    "    module__output_features=2,\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer__momentum=0.9,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=4,\n",
    "    iterator_valid__shuffle=True,\n",
    "    iterator_valid__num_workers=4,\n",
    "    train_split=predefined_split(val_ds),\n",
    "    callbacks=[lrscheduler, checkpoint, freezer],\n",
    "    device='cuda' # comment to train on cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4475639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: output_features.\n",
      "Re-initializing optimizer because the following parameters were re-set: momentum.\n",
      "  epoch    train_loss    valid_acc    valid_loss    cp      lr     dur\n",
      "-------  ------------  -----------  ------------  ----  ------  ------\n",
      "      1        \u001b[36m0.5739\u001b[0m       \u001b[32m0.9346\u001b[0m        \u001b[35m0.2100\u001b[0m     +  0.0010  3.2520\n",
      "      2        \u001b[36m0.4608\u001b[0m       \u001b[32m0.9412\u001b[0m        \u001b[35m0.2067\u001b[0m     +  0.0010  3.1508\n",
      "      3        0.4630       \u001b[32m0.9477\u001b[0m        \u001b[35m0.2052\u001b[0m     +  0.0010  3.2404\n",
      "      4        \u001b[36m0.4561\u001b[0m       0.9346        0.2054        0.0010  3.2204\n",
      "      5        \u001b[36m0.4116\u001b[0m       \u001b[32m0.9542\u001b[0m        \u001b[35m0.1720\u001b[0m     +  0.0010  3.1967\n",
      "      6        0.4347       0.9412        0.1827        0.0010  3.2181\n",
      "      7        0.4326       0.9412        0.2000        0.0010  3.2513\n",
      "      8        \u001b[36m0.3945\u001b[0m       0.9412        0.2218        0.0001  3.2449\n",
      "      9        \u001b[36m0.3566\u001b[0m       0.9477        0.2099        0.0001  3.2322\n",
      "     10        0.3580       0.9477        0.2020        0.0001  3.2090\n",
      "     11        \u001b[36m0.3418\u001b[0m       0.9477        0.1894        0.0001  3.2210\n",
      "     12        0.3656       0.9477        0.1765        0.0001  3.2080\n",
      "     13        \u001b[36m0.2318\u001b[0m       0.9477        \u001b[35m0.1681\u001b[0m        0.0001  3.1847\n",
      "     14        0.3184       0.9477        0.1853        0.0001  3.2081\n",
      "     15        0.3731       0.9412        0.1898        0.0000  3.2225\n",
      "     16        0.2900       0.9477        0.1733        0.0000  3.2359\n",
      "     17        0.3157       0.9346        0.1775        0.0000  3.2290\n",
      "     18        0.3298       0.9412        0.1858        0.0000  3.2260\n",
      "     19        0.3350       0.9542        0.1926        0.0000  3.2160\n",
      "     20        0.3797       0.9412        0.1938        0.0000  3.2520\n",
      "     21        0.3660       0.9542        0.1999        0.0000  3.2064\n",
      "     22        0.2706       0.9542        0.1890        0.0000  3.3080\n",
      "     23        0.2940       0.9477        0.1758        0.0000  3.3490\n",
      "     24        0.3464       0.9477        0.1988        0.0000  3.2175\n",
      "     25        0.2579       0.9477        0.1945        0.0000  3.1980\n"
     ]
    }
   ],
   "source": [
    "net.fit(train_ds, y=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7206ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f8a272a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce30deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
